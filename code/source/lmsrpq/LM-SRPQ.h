#pragma once
#include<iostream>
#include<fstream>
#include<map>
#include<unordered_map>
#include<unordered_set>
#include <queue>
#include <algorithm>
#include <chrono>
#include "forest_struct.h"
#include "../fsa.h"

#define merge_long_long(s, d) (((unsigned long long)s<<32)|d)

using namespace std;


// this is the algorithm fo LM-SRPQ

class LM_forest
{
public:
	streaming_graph* g; // pointer to the streaming graph
	FiniteStateAutomaton* aut;// pointer to the DFA generated by the regular expression
	map<long long, double> aut_scores; // this map stores the depth we estimated for each state in the DFA
	unordered_map<unsigned long long, RPQ_tree*> forests; // unordered map that maps each vertex ID-state pair to the spanning tree rooted at it. the vertex ID and the state is merged into an Unsigned long long 
	map<long long, tree_info_index*> v2t_index; // Maps each state to a tree_info_index, reverse index that maps a graph vertex to the normal trees that contains it.
	map<long long, lm_info_index*> v2l_index; // Maps each state to a lm_info_index, reverse index that maps a graph vertex to the LM trees that contains it.
	unordered_map<unsigned long long, long long> result_pairs;
	long long distinct_results = 0;
	unordered_set<unsigned long long> landmarks; // set of landmarks, vertex ID and states are merged.
	long long landmarks_count = 0;

	LM_forest(streaming_graph* g_, FiniteStateAutomaton* automaton)
	{
		g = g_;
		aut = automaton;
	}
	~LM_forest()
	{
		unordered_map<unsigned long long, RPQ_tree*>::iterator it;
		for (it = forests.begin(); it != forests.end(); it++)
			delete it->second;
		forests.clear();
		map<long long, tree_info_index*>::iterator it2;
		for (it2 = v2t_index.begin(); it2 != v2t_index.end(); it2++)
			delete it2->second;
		map<long long, lm_info_index*>::iterator it3;
		for (it3 = v2l_index.begin(); it3 != v2l_index.end(); it3++)
			delete it3->second;
		v2t_index.clear();
		v2l_index.clear();
		result_pairs.clear();
		landmarks.clear();
		aut_scores.clear();
	}

	void export_result(const string& file_name)
	{
		ofstream fout(file_name);
		for (auto & iter : result_pairs)
		{
			long long src = iter.first >> 32;
			long long dst = iter.first & 0xFFFFFFFF;
			fout << src << "," << dst << "," << iter.second << endl;
		}
		fout.close();
	}

	void update_result(unordered_map<long long, long long>& updated_nodes, long long root_ID, long long lm_time = MAX_INT)
	// first of updated_nodes is vertex ID, second is path timestamps, root_ID can reach these vertices with a qualified regular path.
		// when lm time is set, updated_nodes store path timestamps from a landmark to the vertices, lm time is the path timestamp from root to the landmark, we need to first merge these two parts and then update the result set. 
	{
		for (auto it = updated_nodes.begin(); it != updated_nodes.end(); it++)
		{
			long long dst = it->first;
			long long time = min_custom(it->second, lm_time);
			if (dst == root_ID)
				continue;
			unsigned long long result_pair = (((unsigned long long)root_ID << 32) | dst);
			if (result_pairs.find(result_pair) != result_pairs.end())
				result_pairs[result_pair] = result_pairs[result_pair] > time ? result_pairs[result_pair] : time;
			else {
				result_pairs[result_pair] = time;
				distinct_results++;
			}
			// cout << dst << ", " << time << endl;
		}
	}

	void update_result(vector<pair<long long, long long> >& updated_nodes, long long root_ID, long long lm_time = MAX_INT)
	{
		for (auto & updated_node : updated_nodes)
		{
			long long dst = updated_node.first;
			long long time = min_custom(updated_node.second, lm_time);
			if (dst == root_ID)
				continue;
			unsigned long long result_pair = (((unsigned long long)root_ID << 32) | dst);
			if (result_pairs.find(result_pair) != result_pairs.end())
				result_pairs[result_pair] = result_pairs[result_pair] > time ? result_pairs[result_pair] : time;
			else {
				result_pairs[result_pair] = time;
				distinct_results++;
			}
		}
	}


	void add_index(RPQ_tree* tree_pt, long long v, long long state, long long root_ID) // modify the reverse index when a node is added into a normal tree;
	{
		auto iter = v2t_index.find(state);
		if (iter == v2t_index.end())
			v2t_index[state] = new tree_info_index;
		v2t_index[state]->add_node(tree_pt, v, root_ID);
	}

	void add_lm_index(RPQ_tree* tree_pt, long long v, long long state, long long root_ID, long long root_state) // modify the reverse index when a node is added into an LM tree;
	{
		map<long long, lm_info_index*>::iterator iter = v2l_index.find(state);
		if (iter == v2l_index.end())
			v2l_index[state] = new lm_info_index;
		v2l_index[state]->add_node(tree_pt, v, root_ID, root_state);
	}

	tree_node* add_node(RPQ_tree* tree_pt, long long v, long long state, long long root_ID, tree_node* parent, long long timestamp, long long exp, long long edge_time, bool lm = false) // add a node to a normal tree, bool lm indicating if this node is a landmark.
	{
		add_index(tree_pt, v, state, root_ID);
		tree_node* tmp = tree_pt->add_node(v, state, parent, timestamp, edge_time, exp);
		tmp->lm = lm;
		return tmp;
	}

	tree_node* add_lm_node(RPQ_tree* lm_tree, long long v, long long state, long long root_ID, long long root_state,
		tree_node* parent, long long timestamp, long long exp, long long edge_time, bool lm = false) // add a node to the LM tree .
	{
		add_lm_index(lm_tree, v, state, root_ID, root_state);
		tree_node* tmp = lm_tree->add_node(v, state, parent, timestamp, edge_time, exp);
		tmp->lm = lm;
		return tmp;
	}

	void delete_index(long long v, long long state, long long root)// modify the reverse index when a node is deleted from a normal tree;
	{
		map<long long, tree_info_index*>::iterator iter = v2t_index.find(state);
		if (iter != v2t_index.end())
		{
			iter->second->delete_node(v, root);
			if (iter->second->tree_index.empty())
				v2t_index.erase(iter);
		}
	}

	void delete_lm_index(long long v, long long state, long long root, long long root_state) // modify the reverse index when a node is deleted from an LM tree;
	{
		map<long long, lm_info_index*>::iterator iter = v2l_index.find(state);
		if (iter != v2l_index.end())
		{
			iter->second->delete_node(v, root, root_state);
			if (iter->second->tree_index.empty())
				v2l_index.erase(iter);
		}
	}


	void lm_expand_in_lm_subtree(long long lm, long long state, RPQ_tree* root_lm_tree, long long lm_time, unordered_map<unsigned long long, long long>& updated_nodes)
		// this function is called when a landmark (lm, state) is added into another lm tree root_lm_tree, the timestamp of this node is lm_time, we scan the LM tree of this landmark and update the time_info map
		// in root_lm_tree, besides, we record the nodes where the timestamp in the time_info map of root_lm_tree is updated with updated_nodes, we need to update the result set in the upper layer with these nodes.
	{
		const unsigned long long lm_info = merge_long_long(lm, state);
		if (forests.find(lm_info) == forests.end())
			return;
		RPQ_tree* lm_subtree = forests[lm_info]; // find the LM tree
		for (auto state_iter = lm_subtree->time_info.begin(); state_iter != lm_subtree->time_info.end(); state_iter++) { // scan its time info map
			time_info_index* subtree_index = state_iter->second;
			if (root_lm_tree->time_info.find(state_iter->first) == root_lm_tree->time_info.end()) // if this state is not in the time info map of root_lm_tree yet, add a new lm_info_index
				root_lm_tree->time_info[state_iter->first] = new time_info_index;
			time_info_index* root_index = root_lm_tree->time_info[state_iter->first];
			for (auto iter = subtree_index->index.begin(); iter != subtree_index->index.end(); iter++)
			{
				long long time = min_custom(lm_time, iter->second); // compute the time of latest path from root of root_lm_tree to the node
				if (root_index->index.find(iter->first) == root_index->index.end())
				{
					root_index->index[iter->first] = time;
					updated_nodes[merge_long_long(iter->first, state_iter->first)] = time;
				}
				else {
					if (root_index->index[iter->first] < time)	// if the node is not in the time info map of root_lm_tree before or has a smaller timestamp, we need to update it.
					{
						root_index->index[iter->first] = time;
						updated_nodes[merge_long_long(iter->first, state_iter->first)] = time;
					}
				}
			}
		}
	}

	void lm_expand(tree_node* expand_node, RPQ_tree* lm_tree, unordered_map<unsigned long long, long long>& updated_nodes)
		// this function expand an LM tree given a new node in it, and record the nodes where the timestamp in the time_info map is updated with updated_nodes,
	{
		long long root_ID = lm_tree->root->node_ID;
		long long root_state = lm_tree->root->state;

		updated_nodes[merge_long_long(expand_node->node_ID, expand_node->state)] = expand_node->timestamp;
		lm_tree->add_time_info(expand_node->node_ID, expand_node->state, expand_node->timestamp); // first add the new node into the queue
		priority_queue<tree_node*, vector<tree_node*>, time_compare> q;
		q.push(expand_node);
		while (!q.empty())
		{
			tree_node* tmp = q.top();
			q.pop();
			if (landmarks.find(merge_long_long(tmp->node_ID, tmp->state)) != landmarks.end())
			{
				tmp->lm = true;
				lm_tree->add_lm(merge_long_long(tmp->node_ID, tmp->state));
				lm_expand_in_lm_subtree(tmp->node_ID, tmp->state, lm_tree, tmp->timestamp, updated_nodes);
				continue;
			}

			map<long long, long long> aut_edge = aut->getAllSuccessors(tmp->state); // get the edges acceptable to the src state
			vector<edge_info>sucs = g->get_all_suc(tmp->node_ID); // get out edges of the src node
			for (auto & suc : sucs)
			{
				long long successor = suc.d;
				long long label = suc.label;
				long long time = min_custom(tmp->timestamp, suc.timestamp);
				long long exp = suc.expiration_time;
				if (aut_edge.find(label) == aut_edge.end())
					continue;
				long long dst_state = aut_edge[label];

				if (lm_tree->get_time_info(successor, dst_state) >= time) // prune the branch if there is already a path with no smaller timestamp
					continue;
				if (lm_tree->node_map.find(dst_state) == lm_tree->node_map.end() || lm_tree->node_map[dst_state]->index.find(successor) == lm_tree->node_map[dst_state]->index.end()) // if this node does not exist yet.
				{
					tree_node* new_node = add_lm_node(lm_tree, successor, dst_state, lm_tree->root->node_ID, lm_tree->root->state, tmp, time, exp, suc.timestamp);
					lm_tree->add_time_info(successor, dst_state, time); // add this new node and upadte the time info map
					updated_nodes[merge_long_long(successor, dst_state)] = time;
					q.push(new_node);
				}
				else
				{
					tree_node* dst_pt = lm_tree->node_map[dst_state]->index[successor];
					if (dst_pt->timestamp < time) // if the node exists but has a smaller timestamp
					{
						if (dst_pt->parent != tmp)
							lm_tree->substitute_parent(tmp, dst_pt);
						dst_pt->timestamp = time;
						dst_pt->edge_timestamp = suc.timestamp;
						lm_tree->add_time_info(successor, dst_state, time);
						updated_nodes[merge_long_long(successor, dst_state)] = time;
						q.push(dst_pt);
					}
				}
			}
		}
	}

	void back_track_lm(long long lm, long long state, long long src, long long src_time, long long dst, long long dst_time,
		long long label, long long src_state, long long dst_state, unordered_map<unsigned long long, long long>& updated_nodes, unordered_map<unsigned long long, vector<pair<long long, long long> > >& lm_results)
	// this function performs the backward search from a landmark (lm, state), (src, src_state) and (dst, dst_state) are the src node and dst node of this update, src_time and dst_time are the timestamps of the latest paths from the landmark to these two nodes
		// updated_nodes record the nodes whose timestamp has been updated in the time info map of the landmark, lm_results record the final-state nodes to which the laste path timestamp has been updated for each updated LM tree, it is used in the following normal tree update.
	{
		auto it = v2l_index.find(state);
		if (it != v2l_index.end())
		{
			auto iter = it->second->tree_index.find(lm); // find the list of LM trees containing this landmark.
			if (iter == it->second->tree_index.end())
				return;
			tree_info* cur = iter->second;
			while (cur)
			{
				RPQ_tree* tree_pt = cur->tree;
				long long root_ID = tree_pt->root->node_ID;
				long long root_state = tree_pt->root->state;
				unsigned long long root_info = merge_long_long(root_ID, root_state);
				if ((root_ID == lm && root_state == state) || lm_results.find(root_info) != lm_results.end()) // skip this tree if it is the tree of the landmark itself, or if we have updated the LM tree.
				{
					cur = cur->next;
					continue;
				}
				assert(tree_pt->node_map.find(state) != tree_pt->node_map.end());
				assert(tree_pt->node_map[state]->index.find(lm) != tree_pt->node_map[state]->index.end());
				
				tree_node* lm_node = tree_pt->node_map[state]->index[lm];

				unordered_map<unsigned long long, long long> tracked_nodes;
				long long local_src_time = min_custom(lm_node->timestamp, src_time); // timestamp of the path from the root of tree_pt to src node passing the landmark.
				long long local_dst_time = min_custom(lm_node->timestamp, dst_time); // timestamp of the path from the root of tree_pt to dst node passing the landmark.
				unsigned long long src_info = merge_long_long(src, src_state);
				unsigned long long dst_info = merge_long_long(dst, dst_state);
				if (tree_pt->get_time_info(src, src_state) > local_src_time) // if this is not the latest path to the src node, prune this backtrack
				{
					cur = cur->next;
					continue;
				}
				if (tree_pt->get_time_info(dst, dst_state) >= local_dst_time) { // if there is an existing path to dst node with no smaller timestamp, prune this backtrack.
					cur = cur->next;
					continue;
				}
				for (auto iter2 = updated_nodes.begin(); iter2 != updated_nodes.end(); iter2++)
				{
					long long time = min_custom(lm_node->timestamp, iter2->second);
					if (tree_pt->get_time_info((iter2->first >> 32), (iter2->first & 0xFFFFFFFF)) >= time) // if the time info of the node iter->first can not be updated, continue to next node
						continue;
					tree_pt->add_time_info((iter2->first >> 32), (iter2->first & 0xFFFFFFFF), time); // update the time info.
					tracked_nodes.insert(make_pair(iter2->first, time)); // record this node with another vector, and use it in further backtrack
					if (aut->isFinalState(((iter2->first) & 0xFFFFFFFF))) { // if this is a final state node, record it in lm_result.
						if (lm_results.find(root_info) == lm_results.end())
							lm_results[root_info] = vector<pair<long long, long long> >();
						lm_results[root_info].emplace_back((iter2->first >> 32), time);
					}
				}
				if (!tracked_nodes.empty()) {
					if (root_state == 0) // if this tree has a initial state root, update the result set.
						update_result(lm_results[root_info], tree_pt->root->node_ID);
					back_track_lm(root_ID, root_state, src, local_src_time, dst, local_dst_time, label, src_state, dst_state, tracked_nodes, lm_results);
				}
				tracked_nodes.clear();
				cur = cur->next;
			}
		}
	}


	void insert_edge_lm_tree(long long s, long long d, long long label, long long timestamp, long long exp, long long src_state, long long dst_state, RPQ_tree* lm_tree, unordered_map<unsigned long long, vector<pair<long long, long long> > >& lm_results)
	// insert a new edge (s, src_state) (d, dst_state) with label and timestamp in an LM tree,  record the final-state nodes to which the laste path timestamp has been updated in lm_results.
	{

		long long root_ID = lm_tree->root->node_ID;
		long long root_state = lm_tree->root->state;
		unsigned long long root_info = merge_long_long(root_ID, root_state);
		if (lm_results.find(merge_long_long(root_ID, root_state)) != lm_results.end()) return;
		unordered_map<unsigned long long, long long> updated_nodes;
		assert(lm_tree->node_map.find(src_state) != lm_tree->node_map.end());
		assert(lm_tree->node_map[src_state]->index.find(s) != lm_tree->node_map[src_state]->index.end());
		tree_node* src_pt = lm_tree->node_map[src_state]->index[s];
		unsigned long long src_info = merge_long_long(s, src_state);
		unsigned long long dst_info = merge_long_long(d, dst_state);
		if (src_pt->timestamp < lm_tree->get_time_info(s, src_state)) // if the local path is not the latest, prune this update.
			return;
		if (lm_tree->get_time_info(d, dst_state) >= min_custom(src_pt->timestamp, timestamp)) // if there is an exisiting path to dst with no smaller timestamp, prune this update. 
			return;

		tree_node* dst_pt = nullptr;
		if (lm_tree->node_map.find(dst_state) == lm_tree->node_map.end() || lm_tree->node_map[dst_state]->index.find(d) == lm_tree->node_map[dst_state]->index.end()) // add the dst node if it is not in the tree yet.
			dst_pt = add_lm_node(lm_tree, d, dst_state, lm_tree->root->node_ID, lm_tree->root->state, src_pt, min_custom(src_pt->timestamp, timestamp), exp, timestamp);
		else { // else the new timestamp must be larger than the existing timestamp of dst node in this tree, otherwise we should have returned in the above check.
			dst_pt = lm_tree->node_map[dst_state]->index[d];
			if (dst_pt->timestamp < min_custom(src_pt->timestamp, timestamp))
			{
				if (dst_pt->parent != src_pt)
					lm_tree->substitute_parent(src_pt, dst_pt);
				dst_pt->timestamp = min_custom(src_pt->timestamp, timestamp);
				dst_pt->edge_timestamp = timestamp;
			}
		}
		lm_expand(dst_pt, lm_tree, updated_nodes); // expand from the dst node

		lm_results[root_info] = vector<pair<long long, long long> >(); // we pick the final state nodes from updated_nodes and record them in lm_results.
		for (auto & updated_node : updated_nodes) {
			long long node_ID = (updated_node.first >> 32);
			long long state = (updated_node.first & 0xFFFFFFFF);
			if (aut->isFinalState(state))
				lm_results[root_info].emplace_back(node_ID, updated_node.second);
		}
		if (root_state == 0) // if the root has initial state, we need to update the result set.
			update_result(lm_results[root_info], lm_tree->root->node_ID);
		back_track_lm(root_ID, root_state, s, src_pt->timestamp, d, dst_pt->timestamp, label, src_state, dst_state, updated_nodes, lm_results); // backtrack from this updated LM tree.
		updated_nodes.clear();
	}

	void get_lm_results(long long lm, long long state, long long lm_time, unordered_map<long long, long long>& updated_results)
	{
		// this function is called when a landmark is added into a normal tree, we compute timestamp of new paths passing this landmark and record their timestamps in updated_results.
		// lm_time is the time of landmark in a normal tree, we collect all the final state nodes in the time info map of (lm, state) and merge their timestamp with lm_time to get the timestamp of path from the 
		// normal tree root to the final state node passing the landmark.
		unsigned long long lm_info = merge_long_long(lm, state);
		if (forests.find(lm_info) == forests.end())
			return;
		RPQ_tree* lm_tree = forests[lm_info];
		for (long long final_state : aut->finalStates) {
				if (lm_tree->time_info.find(final_state) != lm_tree->time_info.end())
			{
				for (auto iter = lm_tree->time_info[final_state]->index.begin(); iter != lm_tree->time_info[final_state]->index.end(); iter++)
				{
					long long v = iter->first;
					long long time = min_custom(lm_time, iter->second);
					if (updated_results.find(v) != updated_results.end())
						updated_results[v] = updated_results[v] > time ? updated_results[v] : time;
					else
						updated_results[v] = time;
				}
			}
		}
	}

	void non_lm_expand(tree_node* expand_node, RPQ_tree* tree_pt) // this function is used to expand a normal tree given a new node expand_node;
	{
		long long root_ID = tree_pt->root->node_ID;
		unordered_map<long long, long long> updated_results; // this map records timestamps of final-state nodes to which the timestamp of latest path has been updated
		priority_queue<tree_node*, vector<tree_node*>, time_compare> q;
		q.push(expand_node);
		while (!q.empty())
		{
			tree_node* tmp = q.top();
			q.pop();
			unsigned long long tmp_info = merge_long_long(tmp->node_ID, tmp->state);
			if (aut->isFinalState(tmp->state)) {
				if (updated_results.find(tmp->node_ID) != updated_results.end())
					updated_results[tmp->node_ID] = updated_results[tmp->node_ID] > tmp->timestamp ? updated_results[tmp->node_ID] : tmp->timestamp;
				// todo: use expiration time instead of timestamp
				else
					updated_results[tmp->node_ID] = tmp->timestamp;
			}
			if (landmarks.find(tmp_info) != landmarks.end()) 
			{
				tmp->lm = true;
				tree_pt->add_lm(tmp_info);
				get_lm_results(tmp->node_ID, tmp->state, tmp->timestamp, updated_results); // if this node is a landmark, we directly get the timestamp of its successors from the time info map. // todo: anche qui
				continue;
			}
			else {
				vector<edge_info> vec = g->get_all_suc(tmp->node_ID);  // get all the out edge of the src node
				for (auto & i : vec)
				{
					long long successor = i.d;
					long long edge_label = i.label;
					long long dst_state = aut->getNextState(tmp->state, edge_label); // check if we can travel to a dst state
					if (dst_state == -1)
						continue;
					long long time = min_custom(tmp->timestamp, i.timestamp); // compute timestamp of the dst node
					long long exp = i.expiration_time;
					if (tree_pt->node_map.find(dst_state) == tree_pt->node_map.end() || tree_pt->node_map[dst_state]->index.find(successor) == tree_pt->node_map[dst_state]->index.end()) // add dst node to the tree if it does not exist 
						q.push(add_node(tree_pt, successor, dst_state, tree_pt->root->node_ID, tmp, time, exp, i.timestamp));
					else
					{
						tree_node* dst_pt = tree_pt->node_map[dst_state]->index[successor];
						if (dst_pt->timestamp < time) { // if the timestamp of the new path is larger than the old node time, link dst node to the new path and update its timestamp
							if (dst_pt->parent != tmp)
								tree_pt->substitute_parent(tmp, dst_pt);
							dst_pt->timestamp = time;
							dst_pt->edge_timestamp = i.timestamp;
							q.push(dst_pt);
						}
					}
				}
			}
		}
		update_result(updated_results, tree_pt->root->node_ID); // update the result set with the collected final-state nodes
		updated_results.clear();
	}

	void visit_non_lm_tree(long long s, long long d, long long label, long long timestamp, long long exp, long long src_state, long long dst_state,
		RPQ_tree* tree_pt, unordered_map<unsigned long long, vector<pair<long long, long long> > >& lm_results, unordered_set<long long>& visited)
	{
		// this function is used to update normal trees. normal trees are updated in 2 cases: it contains the src node of the new edge, or it is found in the backward search of a lm tree
		// we do not process normal trees in the back_track_lm function as processing them is different from processing LM trees, and it is better to process LM trees after we process all the LM
		// trees, so that we can directly update these LM trees according to the updated reachable nodes of the LM trees of landmarks in it. 
		if (visited.find(tree_pt->root->node_ID) != visited.end()) // we use a set to filter out the visited normal tree, as we may reach the same normal tree from different backward search branch.
			return;
		visited.insert(tree_pt->root->node_ID);

		long long max_src_time = 0;
		unsigned long long max_src_lm = 0;
		long long max_dst_time = 0;
		unsigned long long max_dst_lm = 0;

		for (auto iter = tree_pt->landmarks.begin(); iter != tree_pt->landmarks.end(); iter++) //we scan the landmarks to check the timestamp of the path to src node and dst node passing them
			// and record the largest timestamp, which is the largest timestamp of paths to the src/ dst node passing landmarks.
		{
			unsigned long long lm_info = *iter;
			if (forests.find(lm_info) != forests.end())
			{
				RPQ_tree* lm_tree = forests[lm_info];
				tree_node* lm_node = tree_pt->find_node((lm_info >> 32), (lm_info & 0xFFFFFFFF));
				long long local_src_time = lm_tree->get_time_info(s, src_state);
				if (min_custom(local_src_time, lm_node->timestamp) > max_src_time) {
					max_src_time = min_custom(local_src_time, lm_node->timestamp);
					max_src_lm = lm_info;
				}
				long long local_dst_time = lm_tree->get_time_info(d, dst_state);
				if (min_custom(local_dst_time, lm_node->timestamp) > max_dst_time) {
					max_dst_time = min_custom(local_dst_time, lm_node->timestamp);
					max_dst_lm = lm_info;
				}
			}
		}

		if (tree_pt->node_map.find(src_state) != tree_pt->node_map.end()) // if the normal tree contians the src node
		{
			tree_node_index* tmp_index = tree_pt->node_map[src_state];
			if (tmp_index->index.find(s) != tmp_index->index.end())
			{
				tree_node* src_pt = tmp_index->index[s];
				if (!src_pt->lm && src_pt->timestamp > max_src_time && min_custom(src_pt->timestamp, timestamp) > max_dst_time) // we expand this normal tree only if the local path has larger timestamp than the paths passing landmarks
					// and no exisiting path has larger, or equal timestamp than the new local path to the dst node 
				{
					long long time = min_custom(src_pt->timestamp, timestamp);
					if (tree_pt->node_map.find(dst_state) == tree_pt->node_map.end() || tree_pt->node_map[dst_state]->index.find(d) == tree_pt->node_map[dst_state]->index.end()) { // need to be checked
						tree_node* dst_pt = add_node(tree_pt, d, dst_state, tree_pt->root->node_ID, src_pt, min_custom(src_pt->timestamp, timestamp), exp, timestamp);
						non_lm_expand(dst_pt, tree_pt);
					}
					else
					{
						tree_node* dst_pt = tree_pt->node_map[dst_state]->index[d];
						if (dst_pt->timestamp < time)
						{
							if (dst_pt->parent != src_pt)
								tree_pt->substitute_parent(src_pt, dst_pt);
							dst_pt->timestamp = time;
							dst_pt->edge_timestamp = timestamp;
							non_lm_expand(dst_pt, tree_pt);
						}
					}
					return;
				}
			}
		}

		// if we do not expand the normal tree, we need to update it with the paths pass landmarks.
		if (max_dst_time > min_custom(max_src_time, timestamp)) // in this case the new edge cannot produce latest paths
			return;
		if (lm_results.find(max_src_lm) != lm_results.end()) { // otherwise we find the landmark passing which the timestamp of path to src is latest, and update the result sets with the recorded updated nodes. 
			long long lm_ID = max_src_lm >> 32;
			long long lm_state = (max_src_lm & 0xFFFFFFFF);
			update_result(lm_results[max_src_lm], tree_pt->root->node_ID, tree_pt->node_map[lm_state]->index[lm_ID]->timestamp);
		}
	}
	
	sg_edge * insert_edge_lmsrpq(long long id, long long s, long long d, long long label, long long timestamp, long long exp) //  a new edge is inserted.
	{
		// now inserting new snapshot graph edge at its arrival
		// update_snapshot_graph(label, timestamp, s, d);
		sg_edge* new_sg_edge = g->insert_edge(id, s, d, label, timestamp, exp);

		if (aut->getNextState(0, label) != -1 && forests.find(merge_long_long(s, 0)) == forests.end()) // we need to build a new tree
		{
			auto* new_tree = new RPQ_tree();
			if (landmarks.find(merge_long_long(s, 0)) == landmarks.end()) // a normal tree
				new_tree->root = add_node(new_tree, s, 0, s, NULL, MAX_INT, exp, MAX_INT);
			else { // an LM tree
				new_tree->root = add_lm_node(new_tree, s, 0, s, 0, NULL, MAX_INT, exp, MAX_INT);
				new_tree->add_time_info(s, 0, MAX_INT);
			}
			forests[merge_long_long(s, 0)] = new_tree;
		}
		vector<pair<long long, long long> >vec = aut->getStatePairsWithTransition(label); // find all the state paris that can accept this label
		for (auto & i : vec) {
			unordered_map<unsigned long long, vector<pair<long long, long long> > > lm_results;
			long long src_state = i.first;
			long long dst_state = i.second;
			if (landmarks.find(merge_long_long(s, src_state)) != landmarks.end()) // if (s, src_state) is a landmark
			{
				RPQ_tree* tree_pt = forests[merge_long_long(s, src_state)];
				insert_edge_lm_tree(s, d, label, timestamp, exp, src_state, dst_state, tree_pt, lm_results); // update the lm tree, backtrack is also called, and the lm trees we find in backtrack and the updated reachable nodes of them are in lm_results.
				unordered_set<long long> visited;
				map<long long, tree_info_index*>::iterator index_iter = v2t_index.find(src_state); // find the trees with the landmark (s, src_state) and update them. such update is a part of the backtrack. We will not expand the normal but only update the result set.
				if (index_iter != v2t_index.end())
				{
					unordered_map<long long, tree_info*>::iterator tree_iter = index_iter->second->tree_index.find(s);
					if (tree_iter != index_iter->second->tree_index.end()) {
						tree_info* tmp = tree_iter->second;
						while (tmp)
						{
							visit_non_lm_tree(s, d, label, timestamp, exp, src_state, dst_state, tmp->tree, lm_results, visited);
							tmp = tmp->next;
						}
					}
				}
				for (auto iter = lm_results.begin(); iter != lm_results.end(); iter++)
				{
					long long lm_ID = (iter->first >> 32);
					long long lm_state = (iter->first & 0xFFFFFFFFF);
					auto index_iter = v2t_index.find(lm_state); // find the normal trees containing other landmarks we find in backtrack and update them.
					if (index_iter != v2t_index.end())
					{
						auto tree_iter = index_iter->second->tree_index.find(lm_ID);
						if (tree_iter != index_iter->second->tree_index.end()) {
							tree_info* tmp = tree_iter->second;
							while (tmp) {
								visit_non_lm_tree(s, d, label, timestamp, exp, src_state, dst_state, tmp->tree, lm_results, visited);
								tmp = tmp->next;
							}
						}
					}
					iter->second.clear();
				}
				visited.clear();
			}
			else {
				map<long long, lm_info_index*>::iterator index_iter = v2l_index.find(src_state); // if (s, src_state) is not a landmark, we need to first update all the LM trees contianing it, and backtrack from them.
				if (index_iter != v2l_index.end())
				{
					unordered_map<long long, tree_info*>::iterator tree_iter = index_iter->second->tree_index.find(s);
					if (tree_iter != index_iter->second->tree_index.end()) {
						tree_info* tmp = tree_iter->second;
						while (tmp)
						{
							insert_edge_lm_tree(s, d, label, timestamp, exp, src_state, dst_state, tmp->tree, lm_results);
							tmp = tmp->next;
						}
					}
				}
				unordered_set<long long> visited;
				map<long long, tree_info_index*>::iterator index_iter2 = v2t_index.find(src_state);
				if (index_iter2 != v2t_index.end())
				{
					unordered_map<long long, tree_info*>::iterator tree_iter = index_iter2->second->tree_index.find(s); // we update all the normal trees containing this node
					if (tree_iter != index_iter2->second->tree_index.end()) {
						tree_info* tmp = tree_iter->second;
						while (tmp)
						{
							visit_non_lm_tree(s, d, label, timestamp, exp, src_state, dst_state, tmp->tree, lm_results, visited);
							tmp = tmp->next;
						}
					}
				}

				for (unordered_map<unsigned long long, vector<pair<long long, long long> > >::iterator iter = lm_results.begin(); iter != lm_results.end(); iter++)
				{
					long long lm_ID = (iter->first >> 32);
					long long lm_state = (iter->first & 0xFFFFFFFFF);
					map<long long, tree_info_index*>::iterator index_iter = v2t_index.find(lm_state); // at last we find the normal trees containing landmarks that we found in backtrack. These normal trees are endpoint of bachtrack branches, we
					// update them together at last so that we ensure every LM tree has been updated, and we can directly use their time info maps safely in the normal tree update.
					if (index_iter != v2t_index.end())
					{
						unordered_map<long long, tree_info*>::iterator tree_iter = index_iter->second->tree_index.find(lm_ID);
						if (tree_iter != index_iter->second->tree_index.end()) {
							tree_info* tmp = tree_iter->second;
							while (tmp) {
								visit_non_lm_tree(s, d, label, timestamp, exp, src_state, dst_state, tmp->tree, lm_results, visited);
								tmp = tmp->next;
							}
						}
					}
					iter->second.clear();
				}
				visited.clear();
			}
			lm_results.clear();
		}
		return new_sg_edge;
	}
	void expand_in_recover(tree_node* expand_node, RPQ_tree* tree_pt, RPQ_tree* lm_tree, bool lm_expand_tree = false) // this is the function to expand a tree when recovering 
		// the subtree of a eliminated landmark. tree_pt is the tree in which we recover the subtree, lm_expand_tree indicating if it is an LM tree. lm_tree is the pointer to the LM tree of the eliminated landmark
		// we carry out expand following this LM tree rather than traverse the graph.
	{
		if (!lm_tree)
			return;

		queue<pair<tree_node*, tree_node*> > q; // each pair store a node in tree_pt and the corresponding node in lm_tree.
 		q.push(make_pair(expand_node, lm_tree->root));
		while (!q.empty())
		{
			pair<tree_node*, tree_node*> tmp = q.front();
			q.pop();
			tree_node* expand_tree_node = tmp.first;
			tree_node* lm_tree_node = tmp.second;
			if (landmarks.find(merge_long_long(lm_tree_node->node_ID, lm_tree_node->state)) != landmarks.end())
			{
				expand_tree_node->lm = true;
				tree_pt->add_lm(merge_long_long(lm_tree_node->node_ID, lm_tree_node->state)); // if we encounter a landmark, we prune this branch, but we donot need to update time info map or the result set, as 
				// no new path will be generated in subtree recover.
				continue;
			}
			tree_node* child = lm_tree_node->child;
			while (child) // scan the child of the lm tree node
			{
				long long v = child->node_ID;
				long long state = child->state;
				long long time = min_custom(child->edge_timestamp, expand_tree_node->timestamp); // compute the timestamp of this child in tree_pt
				long long exp = child->edge_expiration;
				if (tree_pt->node_map.find(state) == tree_pt->node_map.end() || tree_pt->node_map[state]->index.find(v) == tree_pt->node_map[state]->index.end()) 
				{
					tree_node* new_node = NULL; // if it does not exist, we add this node
					if (lm_expand_tree) {
						new_node = add_lm_node(tree_pt, v, state, tree_pt->root->node_ID, tree_pt->root->state, expand_tree_node, time, exp, child->edge_timestamp);
						if (tree_pt->get_time_info(v, state) < time) // in fact I suppose this will not happen, as no new path will be build in recovering subtree, still check it to make sure. 
							tree_pt->add_time_info(v, state, time);
					}
					else
						new_node = add_node(tree_pt, v, state, tree_pt->root->node_ID, expand_tree_node, time, exp, child->edge_timestamp);
					q.push(make_pair(new_node, child));
				}
				else
				{
					tree_node* new_node = tree_pt->node_map[state]->index[v]; // of the node exists, we update its timestamp.
					if (new_node->timestamp < time)
					{
						if (new_node->parent != expand_tree_node)
							tree_pt->substitute_parent(expand_tree_node, new_node);
						new_node->edge_timestamp = child->edge_timestamp;
						new_node->timestamp = time;
						if (lm_expand_tree) {
							if (tree_pt->get_time_info(v, state) < time)
								tree_pt->add_time_info(v, state, time);
						}
						q.push(make_pair(new_node, child));
					}
					else {
						q.push(make_pair(new_node, child)); // it should be noted here, this is necessary. Even if the node already exisits in tree_pt, its successor may be pruned due to a path with larger timestamp in the lm_tree, thus we need to proceed to check.
					}
				}
				child = child->brother;
			}
		}
	}

	void generate_time_info(RPQ_tree* tree_pt) // this function is used to generate time info map for new LM trees. Time info map is generated as a union of nodes in this LM tree, and the time info map of the landmarks in it.
	{
		for (auto iter = tree_pt->node_map.begin(); iter != tree_pt->node_map.end(); iter++)
		{
			long long state = iter->first;
			if (tree_pt->time_info.find(state) == tree_pt->time_info.end())
				tree_pt->time_info[state] = new time_info_index;
			for (auto & node_iter : iter->second->index)
				tree_pt->time_info[state]->index[node_iter.first] = node_iter.second->timestamp;
		}
		for (auto set_iter = tree_pt->landmarks.begin(); set_iter != tree_pt->landmarks.end(); set_iter++)
		{
			unsigned long long lm_info = *set_iter;
			long long lm_ID = (lm_info >> 32);
			long long lm_state = (lm_info & 0xFFFFFFFF);
			tree_node* lm_node = tree_pt->find_node(lm_ID, lm_state);
			long long lm_time = lm_node->timestamp;
			if (forests.find(lm_info) != forests.end())
			{
				RPQ_tree* lm_tree = forests[lm_info];
				for (auto & iter : lm_tree->time_info)
				{
					long long state = iter.first;
					if (tree_pt->time_info.find(state) == tree_pt->time_info.end())
						tree_pt->time_info[state] = new time_info_index;
					for (auto info_iter = iter.second->index.begin(); info_iter != iter.second->index.end(); info_iter++)
						tree_pt->time_info[state]->index[info_iter->first] = tree_pt->time_info[state]->index[info_iter->first] > min_custom(info_iter->second, lm_time) ? tree_pt->time_info[state]->index[info_iter->first] : min_custom(info_iter->second, lm_time);

				}
			}
		}
	}
	void switch_tree_index(RPQ_tree* tree_pt) // this function switch the reverse index of nodes in tree_pt from v2t_index to v2l_index, used when tree_pt is transformed into an LM tree.
	{
		long long root_ID = tree_pt->root->node_ID;
		long long root_state = tree_pt->root->state;
		for (auto iter = tree_pt->node_map.begin(); iter != tree_pt->node_map.end(); iter++)
		{
			for (auto & iter2 : iter->second->index)
			{
				delete_index(iter2.first, iter2.second->state, root_ID);
				add_lm_index(tree_pt, iter2.first, iter2.second->state, root_ID, root_state);
			}
		}
	}

	void switch_tree_index_reverse(RPQ_tree* tree_pt) // this function switch the reverse index of nodes in tree_pt from v2l_index to v2t_index, used when tree_pt is transformed from an LM tree to a normal tree.
	{
		long long root_ID = tree_pt->root->node_ID;
		long long root_state = tree_pt->root->state;
		for (auto iter = tree_pt->node_map.begin(); iter != tree_pt->node_map.end(); iter++)
		{
			for (auto & iter2 : iter->second->index)
			{
				delete_lm_index(iter2.first, iter2.second->state, root_ID, root_state);
				add_index(tree_pt, iter2.first, iter2.second->state, root_ID);
			}
		}
	}
	void recover_subtree(long long v, long long state, RPQ_tree* lm_tree) // this function recovers the subtrees of a deleted landmark (v, state) in normal trees, lm_tree is the LM tree of this landmark.
	{
		auto iter = v2t_index.find(state);
		if (iter != v2t_index.end())
		{
			auto tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end())
			{
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					tree_pt->landmarks.erase(merge_long_long(v, state));
					shrink(tree_pt->landmarks);
					tree_node* lm_node = tree_pt->find_node(v, state);
					lm_node->lm = false;
					if (lm_tree) {
						if (tree_pt->root->node_ID != v || tree_pt->root->state != state)
						{
							bool latest = true;
							for (auto lm_iter = tree_pt->landmarks.begin(); lm_iter != tree_pt->landmarks.end(); lm_iter++) // we first check if the landmark to make sure if the local path is latest
							{
								unsigned long long lm_info = *lm_iter;
								if (forests.find(lm_info) != forests.end())
								{
									tree_node* tmp_lm = tree_pt->find_node((lm_info >> 32), (lm_info & 0xFFFFFFFF));
									if (min_custom(forests[lm_info]->get_time_info(v, state), tmp_lm->timestamp) >= lm_node->timestamp)
									{
										latest = false;
										break;
									}
								}
							}
							if (latest)	// we only recover the subtree if the local path is latest
								expand_in_recover(lm_node, tree_pt, lm_tree);
						}
					}
					tmp = tmp->next;
				}
			}
		}
	}

	void recover_subtree_lm(long long v, long long state, RPQ_tree* lm_tree) // this function recovers the subtrees of a deleted landmark (v, state) in other LM trees, lm_tree is the LM tree of this landmark.
	{
		auto iter = v2l_index.find(state);
		if (iter != v2l_index.end())
		{
			auto tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end()) {
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					tree_pt->landmarks.erase(merge_long_long(v, state));
					shrink(tree_pt->landmarks);
					tree_node* lm_node = tree_pt->find_node(v, state);
					lm_node->lm = false;
					if (lm_tree) {
						if (tree_pt->root->node_ID != v || tree_pt->root->state != state) { // in LM trees, we can quickly  decide if the local path is latest with time info map
							if (tree_pt->get_time_info(v, state) <= lm_node->timestamp) {
								expand_in_recover(lm_node, tree_pt, lm_tree, true);
							}
						}
					}
					tmp = tmp->next;
				}
			}
		}
	}

	void retrieve_subtree(long long v, long long state) // this function delete the subtree of a landmark (v, state) in normal trees.
	{
		auto iter = v2t_index.find(state);
		if (iter != v2t_index.end())
		{
			auto tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end()) {
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					tree_pt->landmarks.insert(merge_long_long(v, state)); // add the new landmark to the landmark set of the normal tree
					tree_node* lm_node = tree_pt->find_node(v, state);
					lm_node->lm = true;
					tree_node* child = lm_node->child;  // carry out a BFS starting from childs of this landmark, and delete all the succesors in its subtree.
					lm_node->child = NULL;
					queue<tree_node*> q;
					while (child)
					{
						q.push(child);
						child = child->brother;
					}
					while (!q.empty())
					{
						tree_node* cur = q.front();
						q.pop();
						delete_index(cur->node_ID, cur->state, tree_pt->root->node_ID);
						child = cur->child;
						while (child)
						{
							q.push(child);
							child = child->brother;
						}
						assert(tree_pt->node_map.find(cur->state) != tree_pt->node_map.end());
						tree_pt->node_map[cur->state]->index.erase(cur->node_ID);
						shrink(tree_pt->node_map[cur->state]->index);
						if (tree_pt->node_map[cur->state]->index.empty()) {
							delete tree_pt->node_map[cur->state];
							tree_pt->node_map.erase(cur->state);
						}
						if (cur->lm) {
							tree_pt->landmarks.erase(merge_long_long(cur->node_ID, cur->state));
							shrink(tree_pt->landmarks);
						}
						delete cur;
						tree_pt->node_cnt--;
					}
					tmp = tmp->next;
				}
			}
		}
	}

	void retrieve_subtree_lm(long long v, long long state, RPQ_tree* lm_tree, unordered_set<unsigned long long>& necessary_nodes) // this function delete the subtree of a landmark (v, state) in LM trees.
		// note that there are some "sensitive " nodes which may be missed in the LM tree of (v, state), we need to compare the LM tree of (v, state) (lm_tree) with each subtree to find these nodes, and add them into 
		// nessary_nodes. They will be added into lm_tree later. Reasons about why they may be missed can be found in the technical report.
	{
		auto iter = v2l_index.find(state);
		if (iter != v2l_index.end())
		{
			auto tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end()) {
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					if (tree_pt->root->node_ID == v && tree_pt->root->state == state) // we need to skip lm_tree itself;
					{
						tmp = tmp->next;
						continue;
					}
					tree_pt->landmarks.insert(merge_long_long(v, state));
					tree_node* lm_node = tree_pt->find_node(v, state);
					lm_node->lm = true;
					tree_node* child = lm_node->child;
					lm_node->child = nullptr;
					queue<tree_node*> q;
					vector<tree_node*> vec;
					unordered_map<unsigned long long, long long> lm_time; // this map stores timestamps of the path from the landmark (v, state) to each successor in the subtree, if we find a latest path in the subtree but not in lm_tree, we need to add nodes
					// in this path to necessary nodes, 
					lm_time[merge_long_long(v, state)] = MAX_INT; // (v, state) is the root of the subtree, and we set its timestamp of MAX_INT
					while (child)
					{
						q.push(child);
						lm_time[merge_long_long(child->node_ID, child->state)] = child->edge_timestamp; // timestamp of the path from the landmark to its child is just the edge between them.
						vec.push_back(child);
						child = child->brother;
					}
					while (!q.empty())
					{
						tree_node* cur = q.front();
						q.pop();
						long long time = lm_time[merge_long_long(cur->node_ID, cur->state)];
						if (time == lm_tree->get_time_info(cur->node_ID, cur->state) && lm_tree->find_node(cur->node_ID, cur->state) == nullptr && necessary_nodes.find(merge_long_long(cur->node_ID, cur->state)) == necessary_nodes.end()) // a latest path, but not in the new lm tree
						{
							tree_node* cur2 = cur; //we find a successor to which the path in the subtree is the latest but not in the lm_tree
							while (cur2 != lm_node) // we store nodes in the path from the landmark to this successor 
							{
								necessary_nodes.insert(merge_long_long(cur2->node_ID, cur2->state));
								cur2 = cur2->parent;
							}
						}
						child = cur->child;
						while (child)
						{
							q.push(child);
							lm_time[merge_long_long(child->node_ID, child->state)] = min_custom(time, child->edge_timestamp);
							vec.push_back(child);  // we store all the tree nodes in a vector, and delete them after we gather all the necessary nodes.
							child = child->brother;
						}
					}
					for (auto & i : vec)
					{
						delete_lm_index(i->node_ID, i->state, tree_pt->root->node_ID, tree_pt->root->state);
						tree_pt->node_map[i->state]->index.erase(i->node_ID);
						shrink(tree_pt->node_map[i->state]->index);
						if (tree_pt->node_map[i->state]->index.empty()) {
							delete tree_pt->node_map[i->state];
							tree_pt->node_map.erase(i->state);
						}
						if (i->lm) {
							tree_pt->landmarks.erase(merge_long_long(i->node_ID, i->state));
							shrink(tree_pt->landmarks);
						}
						delete i;
						tree_pt->node_cnt--;
					}
					tmp = tmp->next;
				}
			}

		}
	}

	void fulfill_new_lm_tree(RPQ_tree* tree_pt, unordered_set<unsigned long long> necessary_nodes)
		// this function add necessary nodes to a new LM tree. these nodes are in paths which are latest but not in the LM tree, they are pruned because there is already a path with the same timestamp passing 
		// other landmarks. However, due to existence of circles, these paths may be in the subtree of the new landmark, and once the subtree is deleted, these paths are missed. thus we need to add them back in
		// the LM tree. Details about how these nodes are missed can be found in the technical report
	{
		vector<tree_node*> original_vec;
		for (auto & iter : tree_pt->node_map)
		{
			for (auto & iter2 : iter.second->index)
				original_vec.push_back(iter2.second);
		}

		for (auto cur : original_vec) // we scan the nodes already in the lm tree one by one, try to expand them to add the necessary nodes.
		{
				queue<tree_node*> q;
			q.push(cur);
			while (!q.empty()) {
				cur = q.front();
				q.pop();
				if (cur->lm) {
					tree_pt->landmarks.insert(merge_long_long(cur->node_ID, cur->state));
					continue;
				}
				vector<edge_info> vec = g->get_all_suc(cur->node_ID);
				for (auto & j : vec)
				{
					long long successor = j.d;
					long long dst_state = aut->getNextState(cur->state, j.label);
					if (dst_state == -1)
						continue;
					long long time = min_custom(cur->timestamp, j.timestamp);
					if (necessary_nodes.find(merge_long_long(successor, dst_state)) == necessary_nodes.end() && tree_pt->get_time_info(successor, dst_state) > time) // we prune a branch if it is not a necessary nodes and the path to it is not the latest.
						continue;
					if (tree_pt->node_map.find(dst_state) != tree_pt->node_map.end() && tree_pt->node_map[dst_state]->index.find(successor) != tree_pt->node_map[dst_state]->index.end()) 
					{
						tree_node* suc_pt = tree_pt->node_map[dst_state]->index[successor];
						if (suc_pt->timestamp < time)
						{
							if (suc_pt->parent != cur)
								tree_pt->substitute_parent(cur, suc_pt);
							suc_pt->edge_timestamp = j.timestamp;
							suc_pt->timestamp = time;
							q.push(suc_pt);
						}
					}
					else
					{
						tree_node* suc_pt = add_lm_node(tree_pt, successor, dst_state, tree_pt->root->node_ID, tree_pt->root->state, cur, time, j.timestamp, landmarks.find(merge_long_long(successor, dst_state)) != landmarks.end());
						q.push(suc_pt);
					}
				}
			}
		}
	}
	RPQ_tree* build_lm_tree(long long v, long long state) // this function build new lm tree for a landmark, we use time info in prune and may miss some nodes, we will add them back with above fulfill_new_lm_tree later .
	{
		auto* new_tree = new RPQ_tree;
		new_tree->root = new_tree->add_node(v, state, NULL, MAX_INT, MAX_INT, 0);
		new_tree->add_time_info(v, state, MAX_INT);
		queue<tree_node*> q;
		q.push(new_tree->root);
		while (!q.empty())
		{
			tree_node* tmp = q.front();
			q.pop();
			if (tmp != new_tree->root && landmarks.find(merge_long_long(tmp->node_ID, tmp->state)) != landmarks.end())
			{
				tmp->lm = true;
				new_tree->add_lm(merge_long_long(tmp->node_ID, tmp->state));
				unordered_map<unsigned long long, long long> tmp_map;
				lm_expand_in_lm_subtree(tmp->node_ID, tmp->state, new_tree, tmp->timestamp, tmp_map); // we only need to update the time info map of the new LM tree with the landmark we find
				tmp_map.clear();
				continue;
			}

			map<long long, long long> aut_edge = aut->getAllSuccessors(tmp->state);
			vector<edge_info>sucs = g->get_all_suc(tmp->node_ID);
			for (auto & suc : sucs)
			{
				long long successor = suc.d;
				long long label = suc.label;
				long long time = min_custom(tmp->timestamp, suc.timestamp);
				if (aut_edge.find(label) == aut_edge.end())
					continue;
				long long dst_state = aut_edge[label];

				if (new_tree->get_time_info(successor, dst_state) >= time) // we pruen the branch once there is already a path with no smaller timestamp. this may lead to some nodes missing. they will be added back later in fulfill_new_lm tree. 
					continue;

				if (new_tree->node_map.find(dst_state) == new_tree->node_map.end() || new_tree->node_map[dst_state]->index.find(successor) == new_tree->node_map[dst_state]->index.end())
				{
					tree_node* new_node = new_tree->add_node(successor, dst_state, tmp, time, suc.timestamp, 0);
					new_tree->add_time_info(successor, dst_state, time);
					q.push(new_node);
				}
				else
				{
					tree_node* dst_pt = new_tree->node_map[dst_state]->index[successor];
					if (dst_pt->timestamp < time)
					{
						if (dst_pt->parent != tmp)
							new_tree->substitute_parent(tmp, dst_pt);
						dst_pt->timestamp = time;
						dst_pt->edge_timestamp = suc.timestamp;
						new_tree->add_time_info(successor, dst_state, time);
						q.push(dst_pt);
					}
				}
			}
		}
		return new_tree;
	}

	void build_v2l_index(RPQ_tree* new_tree) // this function build the reverse index given a new LM tree, we do not build the reverse index during LM tree building, as the LM tree may not become valid. 
	{
		queue<tree_node*> q;
		q.push(new_tree->root);
		while (!q.empty())
		{
			tree_node* tmp = q.front();
			q.pop();
			add_lm_index(new_tree, tmp->node_ID, tmp->state, new_tree->root->node_ID, new_tree->root->state);
			tree_node* child = tmp->child;
			while (child)
			{
				q.push(child);
				child = child->brother;
			}
		}
	}

	bool count_presence(long long id, long long state, long long threshold) // this function count the number of presences of a node in the forest, and returns true once it exceeds the threshold.
	{
		long long sum = 0;
		if (v2t_index.find(state) != v2t_index.end()) {
			tree_info_index* index = v2t_index[state];
			if (index->tree_index.find(id) != index->tree_index.end())
			{
				tree_info* tmp = index->tree_index[id];
				while (tmp)
				{
					sum++;
					if (sum >= threshold)
						return true;
					tmp = tmp->next;
				}
			}
		}
		if (v2l_index.find(state) != v2l_index.end()) {
			lm_info_index* index = v2l_index[state];
			if (index->tree_index.find(id) != index->tree_index.end())
			{
				tree_info* tmp = index->tree_index[id];
				while (tmp)
				{
					sum++;
					if (sum >= threshold)
						return true;
					tmp = tmp->next;
				}
			}
		}
		return false;
	}


	long long recover_subtree_preview(long long v, long long state, RPQ_tree* lm_tree, long long node_budget) // this function predicts the number of nodes we need to add back in normal trees once we delete a landmark from the landmark set.
		// if the number of nodes exceeds the node_budget, we stop the counting and return. lm_tree is the LM tree of the landmark we try to delete. 
	{
		long long node_cnt = 0;
		auto iter = v2t_index.find(state);
		if (iter != v2t_index.end())
		{
			unordered_map<long long, tree_info*>::iterator tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end())
			{
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					for (map<long long, tree_node_index*>::iterator node_iter1 = lm_tree->node_map.begin(); node_iter1 != lm_tree->node_map.end(); node_iter1++)
					{
						for (unordered_map<long long, tree_node*>::iterator node_iter2 = node_iter1->second->index.begin(); node_iter2 != node_iter1->second->index.end(); node_iter2++)
						{
							if (tree_pt->find_node(node_iter2->first, node_iter1->first) == NULL)
							{
								node_budget--; // the number of nodes is predicted as the number of nodes in the lm_tree but not in the normal tree, in this prediction we do not bother to check if the local path to 
								// the landmark is latest, as it needs considerabel computation in normal trees. As a result the prediction will be larger than the fact.
							}
						}
					}
					if (node_budget <= 0)
						return 0;
					tmp = tmp->next;
				}
			}
		}
		return node_budget;
	}
	long long recover_subtree_lm_preview(long long v, long long state, RPQ_tree* lm_tree, long long node_budget) // this function predicts the number of nodes we need to add back in LM trees once we delete a landmark from the landmark set.
		// if the number of nodes exceeds the node_budget, we stop the counting and return. lm_tree is the LM tree of the landmark we try to delete. 
	{
		long long node_cnt = 0;
		map<long long, lm_info_index*>::iterator iter = v2l_index.find(state);
		if (iter != v2l_index.end())
		{
			unordered_map<long long, tree_info*>::iterator tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end())
			{
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					if (tree_pt->root->node_ID == v && tree_pt->root->state == state) // skip lm_tree itself.
					{
						tmp = tmp->next;
						continue;
					}
					tree_node* lm_node = tree_pt->find_node(v, state);
					if (tree_pt->get_time_info(v, state) == lm_node->timestamp) // in LM tree we will check if the local path to the landmark is latest, as it costs little.
					{
						for (map<long long, tree_node_index*>::iterator node_iter1 = lm_tree->node_map.begin(); node_iter1 != lm_tree->node_map.end(); node_iter1++)
						{
							for (unordered_map<long long, tree_node*>::iterator node_iter2 = node_iter1->second->index.begin(); node_iter2 != node_iter1->second->index.end(); node_iter2++)
							{
								if (tree_pt->find_node(node_iter2->first, node_iter1->first) == NULL)
								{
									node_budget--;
								}
							}
						}
					}
					if (node_budget <= 0)
						return 0;
					tmp = tmp->next;
				}
			}
		}
		return node_budget;
	}
	long long retrieve_subtree_preview(long long v, long long state) // the function count the number of nodes in the subtree of (v, state) in normal trees.
	{
		long long node_cnt = 0;
		map<long long, tree_info_index*>::iterator iter = v2t_index.find(state);
		if (iter != v2t_index.end())
		{
			unordered_map<long long, tree_info*>::iterator tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end()) {
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					if (tree_pt->root->node_ID == v && tree_pt->root->state == state) // skip the normal tree of (v, state) itself. As (v, state) is not a landmark yet, there may be a normal tree rooted at it if state = 0;
					{
						tmp = tmp->next;
						continue;
					}
					tree_node* lm_node = tree_pt->find_node(v, state);
					queue<tree_node*> q;
					q.push(lm_node);
					while (!q.empty())
					{
						tree_node* cur = q.front();
						q.pop();
						node_cnt++;
						tree_node* child = cur->child;
						while (child)
						{
							q.push(child);
							child = child->brother;
						}
					}
					node_cnt--; // the landmark itself should not be counted.
					tmp = tmp->next;
				}
			}
		}
		return node_cnt;
	}
	long long retrieve_subtree_lm_preview(long long v, long long state) // the function count the number of nodes in the subtree of (v, state) in LM trees.
	{
		long long node_cnt = 0;
		map<long long, lm_info_index*>::iterator iter2 = v2l_index.find(state);
		if (iter2 != v2l_index.end())
		{
			unordered_map<long long, tree_info*>::iterator tree_iter = iter2->second->tree_index.find(v);
			if (tree_iter != iter2->second->tree_index.end()) {
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					tree_node* lm_node = tree_pt->find_node(v, state);
					queue<tree_node*> q;
					q.push(lm_node);
					while (!q.empty())
					{
						tree_node* cur = q.front();
						q.pop();
						node_cnt++;
						tree_node* child = cur->child;
						while (child)
						{
							q.push(child);
							child = child->brother;
						}
					}
					node_cnt--; // the landmark itself should not be counted.
					tmp = tmp->next;
				}
			}
		}
		return node_cnt;
	}

	void delete_v2h_index(RPQ_tree* tree_pt) // this function delete the reverse index of nodes in a LM tree.
	{
		queue<tree_node*> q;
		q.push(tree_pt->root);
		while (!q.empty())
		{
			tree_node* tmp = q.front();
			q.pop();
			for (tree_node* cur = tmp->child; cur; cur = cur->brother)
				q.push(cur);
			delete_lm_index(tmp->node_ID, tmp->state, tree_pt->root->node_ID, tree_pt->root->state);
		}
	}

	void dynamic_lm_select(double candidate_rate, double benefit_threshold) // the function to select landmarks, first parameter is the candidate selection rate, usually 0.2, the second is the benefit threshold, usually 1.5 
	{
		vector<vertex_score> scores;
		unordered_map<unsigned long long, long long> score_map; //store scores of nodes
		// iterate over the adjacency list of the graph
		// for (unordered_map<long long, neighbor_list>::iterator iter = g->g.begin(); iter != g->g.end(); iter++)
		for (const auto&[fst, snd]: g->adjacency_list) // fst = vertex, snd = successors (vector  of <vertex, edge>)
		{
			long long degree_sum = 0;
			long long id = fst;
			for (auto &[fst, snd] : aut->transitions) // for each state in the automaton
			{
				long long state = fst;
				unsigned long long info = merge_long_long(id, state);
				if (count_presence(id, state, 2)) {  // filter out product graph nodes which appear in less than 2 trees.
					map<long long, long long> degree_map = g->get_src_degree(id);
					degree_sum = 0;
					// only include the edges with acceptable labels in degree counting.
					for (const auto & transition : snd){
						if (degree_map.find(transition.label) != degree_map.end())
							degree_sum += degree_map[transition.label];
					}
					if (degree_sum > 0)
					{
						if (double score = degree_sum * aut_scores[state]; score > 1) {
							scores.emplace_back(id, state, score);
							score_map[merge_long_long(id, state)] = score;
						}
					}
				}
			}
		}
		if (scores.empty())
			return;
		sort(scores.begin(), scores.end()); // socrt the scores.


		auto num = static_cast<long long>(scores.size() * candidate_rate);
		if (num >= scores.size()) {
		    num = scores.size() - 1;
		}
		double bar = scores[scores.size() - num - 1].score; // nodes with score smaller than this bar are not in the candidate set.

		for (auto it = landmarks.begin(); it != landmarks.end(); ) // check current landmarks
		{
			unsigned long long info = *it;
			long long v = (info >> 32);
			long long state = (info & 0xFFFFFFFF);
			RPQ_tree* tree_pt = nullptr;
			if (forests.find(info) != forests.end()) // if the LM tree of this landmark is already deleted because it becomes empty in expiration, this landmark need to be deleted from the landmark set.
				tree_pt = forests[info];
			else
			{
				it = landmarks.erase(it);
				continue;
			}

			if (score_map.find(info) == score_map.end() || score_map[info] < bar) // if it is not a candidate any more.
			{
				it = landmarks.erase(it);
				recover_subtree(v, state, tree_pt);
				recover_subtree_lm(v, state, tree_pt); // rcover the subtrees
				if (state == 0) { // if the state is 0, we need to transform the LM tree back to a normal tree.
					tree_pt->clear_time_info(); // delete the time info map
					switch_tree_index_reverse(tree_pt); // swith the reverse index of the nodes in it from v2h to v2l
				}
				else // else we need to delete this tree.
				{
					delete_v2h_index(tree_pt);
					delete tree_pt;
					forests.erase(info);
				}
				continue;
			}
			else if (state != 0) // if the state is 0, there should be a delta tree with (v state) any way. In this case, as long as there is another subtree with (v, state), selecting it will bring decrease to the forests, thus we donot need to check
			{
				long long node_budget = tree_pt->node_cnt * benefit_threshold; // the number of omitedd nodes in the subtrees need to be larger than this threshold.
				node_budget = recover_subtree_lm_preview(v, state, tree_pt, node_budget);
				if (node_budget > 0)
					node_budget = recover_subtree_preview(v, state, tree_pt, node_budget);
				if (node_budget > 0) // if not, delete it from the landmark
				{
					it = landmarks.erase(it);
					recover_subtree(v, state, tree_pt);
					recover_subtree_lm(v, state, tree_pt);
					delete_v2h_index(tree_pt);
					delete tree_pt;
					forests.erase(info);
				}
				else
					it++;
			}
			else
				it++;
		}

		shrink(landmarks);

		for (long long i = scores.size() - 1; i >= scores.size() - num; i--) // scan candidates
		{
			long long v = scores[i].ID;
			long long state = scores[i].state;
			unsigned long long info = merge_long_long(v, state);
			if (landmarks.find(info) != landmarks.end()) // skip a node if it is already a landmark
				continue;

			RPQ_tree* tree_pt = NULL;
			if (forests.find(info) != forests.end()) { // if there is already a normal tree for it, it mush have state 0, and should be selected as a landmark.
				tree_pt = forests[info];
				generate_time_info(tree_pt);
				switch_tree_index(tree_pt);
				retrieve_subtree(v, state); // delete the subtree in normal trees
				unordered_set<unsigned long long> necessary_nodes;
				retrieve_subtree_lm(v, state, tree_pt, necessary_nodes); // delete subtree in LM trees, and necessary nodes which may be missing in the LM tree building.
				fulfill_new_lm_tree(tree_pt, necessary_nodes); // fulfill the LM tree with necessary nodes.
				necessary_nodes.clear();
				landmarks.insert(info);
				landmarks_count++;
			}
			else // else we need to trade off the benefit and cost
			{
				tree_pt = build_lm_tree(v, state);  // we build the LM tree first. 
				long long node_cost = tree_pt->node_cnt; // cost is the LM tree size
				long long node_benefit = retrieve_subtree_lm_preview(v, state);
				node_benefit += retrieve_subtree_preview(v, state); // benefit is the size of subtrees.
				if (node_benefit < node_cost * benefit_threshold) // if the benefit is not enough, delete the LM tree we just build
					delete tree_pt;
				else // this candidate is a landmark
				{
					forests[info] = tree_pt;		// add the LM tree into forest.
					build_v2l_index(tree_pt); // build reverse index
					retrieve_subtree(v, state);  
					unordered_set<unsigned long long> necessary_nodes;
					retrieve_subtree_lm(v, state, tree_pt, necessary_nodes); // delete subtrees and collect necessary nodes
					fulfill_new_lm_tree(tree_pt, necessary_nodes); // fulfill the LM tree
					necessary_nodes.clear();
					landmarks.insert(info);
					landmarks_count++;
				}
			}
		}
	}

	void output_match(ofstream& fout)
	{
		for (unordered_map<unsigned long long, long long>::iterator iter = result_pairs.begin(); iter != result_pairs.end(); iter++)
			fout << (iter->first >> 32) << " " << (iter->first & 0xFFFFFFFF) << " " << iter->second << endl;
	}
	void count(ofstream& fout) // count the memory used in the algorithm, but exclude the memory of automaton and streaming graph, because they are essential for any algorithm.
	{
		long long us_size = sizeof(unordered_set<long long>); // size of statistics in a unordered_set, which does not change with the key-value type, usually is 56, but may change with the system.
		long long um_size = sizeof(unordered_map<long long, long long>); // size of statistics in a map, which does not change with the key-value type, usually is 56, but may change with the system.
		long long m_size = sizeof(map<long long, long long>); // size of pointers and statistics in a map, which does not change with the key-value type, usually is 48, but may change with the system.

		cout << "\nresult pair size: " << result_pairs.size() << ", memory: " << ((double)(um_size + result_pairs.size() * 24 + result_pairs.bucket_count() * 8) / (1024 * 1024)) << endl;   // number of result vertex pairs, and the memory used to store these results.
		fout << "result pair size: " << result_pairs.size() << ", memory: " << ((double)(um_size + result_pairs.size() * 24 + result_pairs.bucket_count() * 8) / (1024 * 1024)) << endl;

		cout<<"landmark number "<<landmarks.size()<<" tree number "<<forests.size()<<" snapshot graph vertice number "<<g->adjacency_list.size()<<endl;
		fout<<"landmark number "<<landmarks.size()<<" tree number "<<forests.size()<<" snapshot graph vertice number "<<g->adjacency_list.size()<<endl;
		
		long long tree_size = 16 + m_size * 2 + us_size; // size of statistics and pointers in a tree
		double tree_memory = ((double)(um_size + forests.bucket_count() * 8 + forests.size() * (24+tree_size)) / (1024 * 1024)); // forest is a unordered_map (um), each KV is 16 byte, 8 byte long long + 8 byte pointer,
		// plus a pointer pointing to the next KV in the list. Each bucket has a pointer pointing to the head of the value list in this bucket. Memory of following us is computed similarly. size of statistics of each tree is also calculated here.
		double global_lm_memory = ((double)(us_size + landmarks.size() * 16 + landmarks.bucket_count() * 8) / (1024 * 1024)); // size of the unordered_set (us) landmarks, each value is a 8 byte long long, associated with a pointer pointing to next value in the list.
		// each bucket has a pointer pointing to the head of the value list in this bucket. Memory of following us is computed similarly.
		double lm_set_memory = 0; // memory of landmark set in trees.
		double time_info_memory = 0; // memory of time info map
		double lm_node_memory = 0; // memmory of nodes and reverse indexes for LM trees.
		double tree_node_memory = 0; // memmory of nodes and reverse indexes for normal trees.
		for (auto & forest : forests)
		{
			RPQ_tree* tree_pt = forest.second;
			lm_set_memory += tree_pt->landmarks.bucket_count() * 8 + tree_pt->landmarks.size() * 16;
			time_info_memory += tree_pt->time_info.size() * 40; // first layer is a map, and each KV is 24 byte, 3 pointer is associated (parent, left child, right child)
			for (map<long long, time_info_index*>::iterator iter2 = tree_pt->time_info.begin(); iter2 != tree_pt->time_info.end(); iter2++) {
				time_info_memory += um_size + iter2->second->index.bucket_count() * 8 + iter2->second->index.size() * 16; // second layer is a um, and each KV is 8 byte.
			}
			unsigned long long info = merge_long_long(tree_pt->root->node_ID, tree_pt->root->state);
			bool lm_root = false;
			if (landmarks.find(info) != landmarks.end())
				lm_root = true; // marks if it is an LM tree
			double node_memory = 0;
			node_memory += tree_pt->node_map.size() * 40; // first layer of the node map is a map
			for (map<long long, tree_node_index*>::iterator iter2 = tree_pt->node_map.begin(); iter2 != tree_pt->node_map.end(); iter2++)
				node_memory += um_size + iter2->second->index.bucket_count() * 8 + iter2->second->index.size() * (24+48); // second layer is a um, each KV is 16 byte, memory of the tree node is also computed here.
			if (lm_root)
				lm_node_memory += node_memory;
			else
				tree_node_memory += node_memory;
		}
		lm_set_memory = ((lm_set_memory) / (1024 * 1024));
		time_info_memory = (time_info_memory / (1024 * 1024));
		cout << "memory usage of time info in lm trees: " << time_info_memory << endl;
		fout << "memory usage of time info in lm trees: " << time_info_memory << endl;

		// calculate memory of the reverse index from node to tree.

		long long lm_node_num = 0;
		lm_node_memory += m_size + v2l_index.size() * 40; // firt layer is a map
		for (map<long long, lm_info_index*>::iterator iter = v2l_index.begin(); iter != v2l_index.end(); iter++)
		{
			lm_node_memory += um_size + m_size; // each second layer lm_info_index has a um and a map
			lm_node_memory += iter->second->tree_index.bucket_count() * 8 + iter->second->tree_index.size() * 24;  // memory of the um, each KV has 16 bytes.
			for (unordered_map<long long, tree_info*>::iterator iter2 = iter->second->tree_index.begin(); iter2 != iter->second->tree_index.end(); iter2++)
			{
				tree_info* tmp = iter2->second;
				while (tmp)
				{
					lm_node_num++; // this is the reverse index unit number, as well as the number of nodes in LM trees.
					tmp = tmp->next;
				}
			}
			lm_node_memory += iter->second->info_map.size() * 48; // each KV of the map has size 24
		}
		lm_node_memory += lm_node_num * 24; // memory of the reverse index units (tree_info)
		lm_node_memory = (lm_node_memory / (1024 * 1024));
		cout << "node number in LM tree: " << lm_node_num << ", memory: " << lm_node_memory << endl;
		fout << "node number in LM tree: " << lm_node_num << ", memory: " << lm_node_memory << endl;

		// similar as above, but in normal trees.
		long long tree_node_num = 0;
		tree_node_memory += m_size + v2t_index.size() * 40;
		for (map<long long, tree_info_index*>::iterator iter = v2t_index.begin(); iter != v2t_index.end(); iter++)
		{
			tree_node_memory += um_size + m_size;
			tree_node_memory += iter->second->tree_index.bucket_count() * 8 + iter->second->tree_index.size() * 24;
			for (unordered_map<long long, tree_info*>::iterator iter2 = iter->second->tree_index.begin(); iter2 != iter->second->tree_index.end(); iter2++)
			{
				tree_info* tmp = iter2->second;
				while (tmp)
				{
					tree_node_num++;
					tmp = tmp->next;
				}
			}
			tree_node_memory += iter->second->info_map.size() * 40;
		}
		tree_node_memory += tree_node_num * 24;
		tree_node_memory = (tree_node_memory / (1024 * 1024));
		cout << "node number in normal tree: " << tree_node_num << ", memory: " << tree_node_memory << endl;
		// cout << "total memory besides result set: " << (tree_memory + global_lm_memory + lm_set_memory + time_info_memory + lm_node_memory + tree_node_memory) << endl;
		// fout << "node number in normal tree: " << tree_node_num << ", memory: " << tree_node_memory << endl;
		// fout << "total memory besides result set: " << (tree_memory + global_lm_memory + lm_set_memory + time_info_memory + lm_node_memory + tree_node_memory) << endl;
		// cout << endl;
		// fout << endl;
	}

	void results_update(long long time) // this function deletes out dated results with timestamp smaller than given time
	{
		if (time <= 0)
			return;
		for (auto iter = result_pairs.begin(); iter != result_pairs.end();)
		{
			if (iter->second < time) {
				iter = result_pairs.erase(iter);
			}
			else
				iter++;
		}
		shrink(result_pairs);
	}

	void erase_tree_node(RPQ_tree* tree_pt, tree_node* child)  // this function deletes subtree rooted at the given node (child) in a normal tree (tree_pt)
	{
		queue<tree_node*> q;
		q.push(child);
		tree_pt->separate_node(child); // 'child' is disconnected with its parent,other nodes do not need to call this function, as there parents and brothers are all deleted;
		while (!q.empty())
		{
			tree_node* tmp = q.front();
			q.pop();
			for (tree_node* cur = tmp->child; cur; cur = cur->brother)
				q.push(cur);
			tree_pt->remove_node(tmp);
			delete_index(tmp->node_ID, tmp->state, tree_pt->root->node_ID);
			delete tmp;
		}
	}

	void erase_lm_tree_node(RPQ_tree* tree_pt, tree_node* child, vector<unsigned long long>& deleted) // this function deletes subtree rooted at the given node (child) in an LM tree (tree_pt), different from above,
		// we need to record the deleted nodes with a vector deleted, we will use these nodes in a backward search later to delete time info map in precursors of this LM tree in the dependency graph.
	{
		if (tree_pt->root == child) return;// if the root is deleted, we need to delete the whole tree.
		queue<tree_node*> q;
		q.push(child);
		tree_pt->separate_node(child); // 'child' is disconnected with its parent,other nodes do not need to call this function, as there parents and brothers are all deleted;
		while (!q.empty())
		{
			tree_node* tmp = q.front();
			q.pop();
			deleted.push_back(merge_long_long(tmp->node_ID, tmp->state));
			for (tree_node* cur = tmp->child; cur; cur = cur->brother)
				q.push(cur);
			tree_pt->remove_node(tmp);
			delete_lm_index(tmp->node_ID, tmp->state, tree_pt->root->node_ID, tree_pt->root->state);
			delete tmp;
		}
	}


	void expire_backtrack(long long v, long long state, long long expired_time, vector<unsigned long long>& deleted_results, unordered_set<unsigned long long>& visited)
		// this function performs a backward search from a landmark v, state). Deleted_results are the nodes where the path from landmark to them has expired. entry of these nodes in the time info map of its precursor LM trees
		// may also expire, we need to check them in the search, visited records the visited LM trees, in case of repeated check. expired_time is the tail of the sliding window, entries with timestamp smaller than it expire.
	{
		auto iter = v2l_index.find(state);
		if (iter != v2l_index.end())
		{
			auto tree_iter = iter->second->tree_index.find(v);
			if (tree_iter != iter->second->tree_index.end()) {
				tree_info* tmp = tree_iter->second;
				while (tmp)
				{
					RPQ_tree* tree_pt = tmp->tree;
					unsigned long long tree_info = merge_long_long(tree_pt->root->node_ID, tree_pt->root->state);
					if (visited.find(tree_info) != visited.end())
					{
						tmp = tmp->next;
						continue;
					}
					visited.insert(tree_info);
					vector<unsigned long long> tracked_nodes;
					for (unsigned long long dst_info : deleted_results)
					{
							long long dst_state = (dst_info & 0xFFFFFFFF);
						long long dst_ID = (dst_info >> 32);
						if (tree_pt->time_info.find(dst_state) != tree_pt->time_info.end())
						{
							if (tree_pt->time_info[dst_state]->index.find(dst_ID) != tree_pt->time_info[dst_state]->index.end())
							{
								if (tree_pt->time_info[dst_state]->index[dst_ID] < expired_time) { // check if the time info entry of a node is expired.
									tree_pt->time_info[dst_state]->index.erase(dst_ID);
									shrink(tree_pt->time_info[dst_state]->index);
								}
								if (tree_pt->time_info[dst_state]->index.empty())
									tree_pt->time_info.erase(dst_state);
							}
						}
						tracked_nodes.push_back(dst_info); // it should be noted that we need to further backtrack up with all nodes in deleted_results, otherwise errors will happen, some expired time info entries will be left
						// this is caused by circles in the dependency graph.
					}
					if (!tracked_nodes.empty())
						expire_backtrack(tree_pt->root->node_ID, tree_pt->root->state, expired_time, tracked_nodes, visited);
					tracked_nodes.clear();
					tmp = tmp->next;
				}
			}
		}
	}
	void expire_per_lm_tree(long long v, long long state, RPQ_tree* tree_pt, long long expired_time) // carry out expiration in an LM tree tree_pt given a possibly expired node (v, state) and tail of sliding window expired_time.
	{
		if (tree_pt->node_map.find(state) != tree_pt->node_map.end())
		{
			if (tree_pt->node_map[state]->index.find(v) != tree_pt->node_map[state]->index.end()) {
				tree_node* dst_pt = tree_pt->node_map[state]->index[v];
				if (dst_pt->edge_expiration < expired_time) { // if this node index expired, we need to erase its subtree and carry out expire_backtrack
					vector<unsigned long long> erased;
					vector<unsigned long long> deleted;
					unordered_set<unsigned long long> visited;
					erase_lm_tree_node(tree_pt, dst_pt, erased);
					if (!erased.empty()) {
 						for (unsigned long long dst_info : erased)
						{
								if (landmarks.find(dst_info) != landmarks.end()) // if a landmark is deleted, we need to check if it will influence the time info map
							{
								if (forests.find(dst_info) != forests.end())
								{
									RPQ_tree* dst_tree = forests[dst_info];
									for (auto & dst_iter : dst_tree->time_info)
									{
										long long state2 = dst_iter.first;
										if (tree_pt->time_info.find(state2) == tree_pt->time_info.end())
											continue;
										time_info_index* target_index = tree_pt->time_info[state2];
										// scan the time info in the LM tree of the deleted landmark, as the paths to nodes in this time info map passing the deleted landmark expire, time info of these nodes
										// in tree_pt may also expire, we need to check, and record the expired ones.
										for (auto time_iter = dst_iter.second->index.begin(); time_iter != dst_iter.second->index.end(); time_iter++)
										{
											if (target_index->index.find(time_iter->first) != target_index->index.end())
											{
												if (target_index->index[time_iter->first] < expired_time) {
													target_index->index.erase(time_iter->first);
													deleted.push_back(merge_long_long(time_iter->first, state2));
												}
											}
										}
										shrink(target_index->index);
										if (target_index->index.empty())
											tree_pt->time_info.erase(state2);
									}
								}
							}
							long long dst_ID = (dst_info >> 32);
							long long dst_state = (dst_info & 0xFFFFFFFF);
							if (tree_pt->time_info.find(dst_state) != tree_pt->time_info.end()) {  // check time info of this deleted node.
								if (tree_pt->time_info[dst_state]->index.find(dst_ID) != tree_pt->time_info[dst_state]->index.end())
								{
									if (tree_pt->time_info[dst_state]->index[dst_ID] < expired_time) {
										tree_pt->time_info[dst_state]->index.erase(dst_ID);
										shrink(tree_pt->time_info[dst_state]->index);
										if (tree_pt->time_info[dst_state]->index.empty())
											tree_pt->time_info.erase(dst_state);
										deleted.push_back(dst_info);
									}
								}
							}

						}
						erased.clear();
						visited.insert(merge_long_long(tree_pt->root->node_ID, tree_pt->root->state));
						if (!deleted.empty())
							expire_backtrack(tree_pt->root->node_ID, tree_pt->root->state, expired_time, deleted, visited);
						deleted.clear();
						visited.clear();
					}
				}
			}
		}
	}

	void expire_per_tree(long long v, long long state, RPQ_tree* tree_pt, long long expire_time) // expire in normal tree, we only need to delete the nodes in the subtree.
	{
		if (tree_pt->node_map.find(state) != tree_pt->node_map.end())
		{
			if (tree_pt->node_map[state]->index.find(v) != tree_pt->node_map[state]->index.end()) {
				tree_node* dst_pt = tree_pt->node_map[state]->index[v];
				if (dst_pt->edge_expiration < expire_time)
					erase_tree_node(tree_pt, dst_pt);
			}

		}
	}

	void expire(long long current_time, const vector<edge_info>& deleted_edges) //given current time, carry out an expiration in the forest.
	{
		long long expire_time = current_time;
		// results_update(expire_time); // delete expired results.
		// g->expire(current_time, deleted_edges); // delete expired edges in the graph
		unordered_set<unsigned long long> visited_pair;
		for (auto & deleted_edge : deleted_edges)
		{
			long long dst = deleted_edge.d;
			long long label = deleted_edge.label;
			vector<pair<long long, long long> > vec = aut->getStatePairsWithTransition(label); // dst node of the expired edge may be root of expired subtrees, get all the possible dst states/
			for (auto & j : vec) {
				long long dst_state = j.second;
				if (dst_state == -1)
					continue;
				if (visited_pair.find(merge_long_long(dst, dst_state)) != visited_pair.end()) // some dst nodes may be checked before, and need not to be checked again.
					continue;
				visited_pair.insert(merge_long_long(dst, dst_state));
				auto iter = v2t_index.find(dst_state);
				if (iter != v2t_index.end())
				{
					auto tree_iter = iter->second->tree_index.find(dst);
					if (tree_iter != iter->second->tree_index.end())
					{
						vector<RPQ_tree*> tree_to_delete;
						tree_info* tmp = tree_iter->second;
						while (tmp)
						{
							tree_to_delete.push_back(tmp->tree); // we first record the tree list and then check them one by one, as the deletion may change the tree list. 
							tmp = tmp->next;
						}
						for (auto & k : tree_to_delete)
						{
							expire_per_tree(dst, dst_state, k, expire_time);
							if (k->root->child == nullptr)
							{
								delete_index(k->root->node_ID, k->root->state, k->root->node_ID);
								forests.erase(merge_long_long(k->root->node_ID, k->root->state));
								delete k;
							}
						}
						shrink(forests);
						tree_to_delete.clear();
					}
				}
				//expire in LM trees.
				auto iter2 = v2l_index.find(dst_state);
				if (iter2 != v2l_index.end())
				{
					auto tree_iter = iter2->second->tree_index.find(dst);
					if (tree_iter != iter2->second->tree_index.end())
					{
						vector<RPQ_tree*> tree_to_delete;
						tree_info* tmp = tree_iter->second;
						while (tmp)
						{
							tree_to_delete.push_back(tmp->tree);
							tmp = tmp->next;
						}
						for (auto & k : tree_to_delete)
						{
							expire_per_lm_tree(dst, dst_state, k, expire_time);
							if (k->root->child == nullptr)
							{
								delete_lm_index(k->root->node_ID, k->root->state, k->root->node_ID, k->root->state);
								forests.erase(merge_long_long(k->root->node_ID, k->root->state));
								if (landmarks.find(merge_long_long(k->root->node_ID, k->root->state)) != landmarks.end()) {
									landmarks.erase(merge_long_long(k->root->node_ID, k->root->state));
									recover_subtree(k->root->node_ID, k->root->state, NULL);
									recover_subtree_lm(k->root->node_ID, k->root->state, NULL);
								}

								delete k;
							}
						}
						shrink(forests);
						tree_to_delete.clear();
					}
				}
			}
			//time_info_expire(expire_time);
		}

	}



};
